{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"twitter_data.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO/wcMw9koW7FkzICF1sAKB"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"sk0wM_uzdNxQ","colab_type":"code","outputId":"8d9c1db0-baaa-4d65-8bb6-e8cf9c44a494","executionInfo":{"status":"ok","timestamp":1589883779516,"user_tz":-330,"elapsed":5701,"user":{"displayName":"Sudhir Kakumanu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirT7xOX0jzroV3IGw0xkkVD0DpWUDOFdhtV0BWuG0=s64","userId":"16884750786484094249"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["# !pip3 install tweepy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting tweepy\n","  Downloading tweepy-3.8.0-py2.py3-none-any.whl (28 kB)\n","Requirement already satisfied: six>=1.10.0 in /home/develop_inferencia_ai/.local/lib/python3.7/site-packages (from tweepy) (1.12.0)\n","Collecting PySocks>=1.5.7\n","  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests>=2.11.1 in /home/develop_inferencia_ai/.local/lib/python3.7/site-packages (from tweepy) (2.21.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/develop_inferencia_ai/.local/lib/python3.7/site-packages (from tweepy) (1.3.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.11.1->tweepy) (2.6)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.11.1->tweepy) (1.22)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.11.1->tweepy) (2018.1.18)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /home/develop_inferencia_ai/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n","Installing collected packages: PySocks, tweepy\n","Successfully installed PySocks-1.7.1 tweepy-3.8.0\n","\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1 is available.\n","You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jvCI5YJxbv1Y","colab_type":"code","colab":{}},"source":["import os\n","import urllib\n","from datetime import datetime\n","import sys\n","import pandas as pd\n","\n","try:\n","    import json\n","except ImportError:\n","    import simplejson as json\n","\n","# Import the tweepy library\n","import tweepy\n","\n","import logging\n","logger = logging.getLogger(__name__)\n","logging.basicConfig(level=logging.DEBUG,\n","                      format='[%(asctime)s.%(msecs)03d] [%(levelname)s] (%(threadName)-9s) %(message)s',\n","                      datefmt='%m-%d %H:%M:%S')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BJWVO9c-6oo4","colab_type":"code","colab":{}},"source":["def get_tweets_by_hashtag(auth, textToSearch, num_of_results):\n","    tweets_lis = []\n","    \n","    api = tweepy.API(auth)\n","    for tweet_info in tweepy.Cursor(api.search, q=textToSearch, lang = 'en', tweet_mode='extended', rpp=100).items(num_of_results):                 \n","      msg = {}\n","      if 'retweeted_status' in dir(tweet_info):\n","          tweet=tweet_info.retweeted_status\n","          msg.update({'expanded_url': tweet.entities['media'][0]['expanded_url']})\n","      else:\n","          tweet=tweet_info\n","\n","      msg.update({'created_at': tweet.created_at, 'full_text': tweet.full_text, 'name': tweet.user.name, 'user_id':tweet.user.id, 'tweet_id': tweet.id})\n","\n","      tweets_list.append(msg)\n","    \n","    return tweets_list\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F8jlC83z7M6w","colab_type":"code","colab":{}},"source":["def get_tweets_by_textsearch(auth, textToSearch, num_of_results):\n","    # Create the api to connect to twitter with your creadentials\n","    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True, parser=tweepy.parsers.JSONParser())\n","\n","    search_results = api.search(q=textToSearch+' filter:native_video', count=num_of_results)\n","    # print(len(search_results['statuses']))\n","    # print(search_results['statuses'][0])\n","\n","    return search_results"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B1-a2dTFrEYU","colab_type":"code","colab":{}},"source":["def prepare_dict(tweet, real_fact):\n","    temp = {}\n","    if real_fact == True:\n","      temp.update({'expanded_url': tweet.entities['media'][0]['expanded_url'], 'created_at': tweet.created_at, 'full_text': tweet.full_text, 'name': tweet.user.name, 'user_id':tweet.user.id, 'tweet_id': tweet.id, 'real_fact': False, 'lang':tweet.lang})\n","    else:\n","      temp.update({'expanded_url': tweet.entities['urls'], 'created_at': tweet.created_at, 'full_text': tweet.full_text, 'name': tweet.user.name, 'user_id':tweet.user.id, 'tweet_id': tweet.id, 'real_fact': True, 'lang':tweet.lang})\n","    return temp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqhuyYgG77vd","colab_type":"code","colab":{}},"source":["def get_tweets_by_screen_name(auth, screen_name, num_of_results):\n","    api = tweepy.API(auth)\n","    \n","    #initialize a list to hold all the tweepy Tweets\n","    alltweets = []  \n","    \n","    #make initial request for most recent tweets (200 is the maximum allowed count)\n","    new_tweets = api.user_timeline(screen_name = screen_name,count=num_of_results, tweet_mode=\"extended\")\n","    \n","    #save most recent tweets\n","    alltweets.extend(new_tweets)\n","    \n","    #save the id of the oldest tweet less one\n","    oldest = alltweets[-1].id - 1\n","    \n","    iter = 0\n","    #keep grabbing tweets until there are no tweets left to grab\n","    while len(new_tweets) > 0:\n","        print(f\"getting tweets before {oldest}\")\n","        \n","        #all subsiquent requests use the max_id param to prevent duplicates\n","        new_tweets = api.user_timeline(screen_name = screen_name,count=num_of_results,max_id=oldest, tweet_mode=\"extended\")\n","        \n","        #save most recent tweets\n","        alltweets.extend(new_tweets)\n","        \n","        #update the id of the oldest tweet less one\n","        oldest = alltweets[-1].id - 1\n","        \n","        print(f\"...{len(alltweets)} tweets downloaded so far\")\n","\n","    \n","    #transform the tweepy tweets into a 2D array that will populate the csv \n","    # outtweets = [{'expanded_url': tweet.entities['media'][0]['expanded_url'], 'created_at': tweet.created_at, 'full_text': tweet.full_text, 'name': tweet.user.name, 'user_id':tweet.user.id, 'tweet_id': tweet.id} for tweet in alltweets if ((tweet.lang == 'en') and (tweet.full_text.find('MyGovFactCheck') != -1))]  \n","    outtweets = [ prepare_dict(tweet, True) if ((tweet.lang == 'en') and (tweet.full_text.find('MyGovFactCheck') != -1)) else prepare_dict(tweet, False) for tweet in alltweets]\n","    \n","    return outtweets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"seJY-xHvdcOC","colab_type":"code","colab":{}},"source":["def search_api(textToSearch, num_of_results, tw_type, datefrom, dateto):\n","    tweets_list = []\n","\n","    try:\n","        textToSearch = textToSearch.encode(\"utf-8\")\n","    except:\n","        logging.exception(\"*****KNOWN ERROR HANDLED****** textToSearch encode utf-8\")\n","        textToSearch = textToSearch\n","\n","    print(textToSearch)\n","    textToSearch = urllib.parse.quote(textToSearch)\n","\n","    # Variables that contains the user credentials to access Twitter API \n","    ACCESS_TOKEN = 'XXXXXXXXXXXXXXXXXXXXXX'\n","    ACCESS_SECRET = 'XXXXXXXXXXXXXXXXXXXXXX'\n","    CONSUMER_KEY = 'XXXXXXXXXXXXXXXXXXXXXX'\n","    CONSUMER_SECRET = 'XXXXXXXXXXXXXXXXXXXXXX'\n","\n","    # Setup tweepy to authenticate with Twitter credentials:\n","    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n","    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n","\n","    if tw_type.find('hashtag') != -1:\n","      tweets_list = get_tweets_by_hashtag(auth, textToSearch, num_of_results)\n","    elif tw_type.find('screen_name') != -1:\n","      tweets_list = get_tweets_by_screen_name(auth, textToSearch, num_of_results)\n","    elif tw_type.find('textsearch') != -1:\n","      tweets_list = get_tweets_by_textsearch(auth, textToSearch, num_of_results)\n","\n","    return tweets_list"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zD2takqrfw1c","colab_type":"code","colab":{}},"source":["MAX_TWEETS = 5000\n","\n","# tweets_list = search_api(\"#MyGovFactCheck\", MAX_TWEETS, 'hashtag',  '2019-01-01', '2019-03-01')\n","tweets_list = search_api(\"mygovindia\", MAX_TWEETS, 'screen_name',  '2019-01-01', '2019-03-01')\n","# tweets_list = search_api(\"mygovindia\", MAX_TWEETS, None,  '2019-01-01', '2019-03-01')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9aRCYlP4iZ4h","colab_type":"code","outputId":"ff2f6b60-45d8-4bca-8442-fd44677fd4b1","executionInfo":{"status":"ok","timestamp":1589907473196,"user_tz":-330,"elapsed":265,"user":{"displayName":"Sudhir Kakumanu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirT7xOX0jzroV3IGw0xkkVD0DpWUDOFdhtV0BWuG0=s64","userId":"16884750786484094249"}},"colab":{"base_uri":"https://localhost:8080/","height":629}},"source":["df = pd.DataFrame(tweets_list)\n","df = df.sort_values(by='created_at', ascending=False)\n","df = df[df.lang == 'en']\n","df = df[df.expanded_url.str.len() != 0] \n","df = df.reset_index(drop=True)\n","print(df.head(10))\n","print(len(df))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["           created_at                                       expanded_url  \\\n","0 2020-05-19 13:18:12  [{'url': 'https://t.co/voPQh6JXvn', 'expanded_...   \n","1 2020-05-19 10:53:55  [{'url': 'https://t.co/NtOxikeknW', 'expanded_...   \n","2 2020-05-19 09:15:33  [{'url': 'https://t.co/tYTfLBU5ka', 'expanded_...   \n","3 2020-05-19 09:07:16  [{'url': 'https://t.co/D5UL7YGQLx', 'expanded_...   \n","4 2020-05-19 09:01:14  [{'url': 'https://t.co/D5UL7YpfTZ', 'expanded_...   \n","5 2020-05-19 08:56:41  [{'url': 'https://t.co/D5UL7YGQLx', 'expanded_...   \n","6 2020-05-19 08:49:20  [{'url': 'https://t.co/D5UL7YGQLx', 'expanded_...   \n","7 2020-05-19 08:44:34  [{'url': 'https://t.co/voPQh6JXvn', 'expanded_...   \n","8 2020-05-19 08:40:47  [{'url': 'https://t.co/D5UL7YGQLx', 'expanded_...   \n","9 2020-05-19 08:32:27  [{'url': 'https://t.co/D5UL7YGQLx', 'expanded_...   \n","\n","                                           full_text lang        name  \\\n","0  Vande Bharat Mission: Operating Samudra Setu o...   en  MyGovIndia   \n","1  Delhi Police has truly proved to be #DilKiPoli...   en  MyGovIndia   \n","2  No Indian will be left behind, in the war agai...   en  MyGovIndia   \n","3  #Lockdown 4.0: Aarogya Setu App to act as a sh...   en  MyGovIndia   \n","4  #Lockdown 4.0: States and UTs will decide on a...   en  MyGovIndia   \n","5  #Lockdown 4.0: Norms for night curfew and prot...   en  MyGovIndia   \n","6  #Lockdown 4.0: National Directives for the COV...   en  MyGovIndia   \n","7  #Lockdown 4.0: Take a look at the special meas...   en  MyGovIndia   \n","8  #Lockdown 4.0: Take a look at the activities p...   en  MyGovIndia   \n","9  #Lockdown 4.0: Activities permitted across the...   en  MyGovIndia   \n","\n","   real_fact             tweet_id     user_id  \n","0       True  1262734299867963392  2686834802  \n","1       True  1262697991661662211  2686834802  \n","2       True  1262673235906146306  2686834802  \n","3       True  1262671150837981185  2686834802  \n","4       True  1262669632919556098  2686834802  \n","5       True  1262668490189619201  2686834802  \n","6       True  1262666640119828481  2686834802  \n","7       True  1262665440163016704  2686834802  \n","8       True  1262664488672563200  2686834802  \n","9       True  1262662387846402049  2686834802  \n","1019\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R9J0SgZMjyny","colab_type":"code","outputId":"cc2f7583-968b-4173-eea0-dd4da122b201","executionInfo":{"status":"ok","timestamp":1589907558511,"user_tz":-330,"elapsed":212,"user":{"displayName":"Sudhir Kakumanu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirT7xOX0jzroV3IGw0xkkVD0DpWUDOFdhtV0BWuG0=s64","userId":"16884750786484094249"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["print(len(df[df['real_fact']==False]))\n","print((df.iloc[0].full_text))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["42\n","Vande Bharat Mission: Operating Samudra Setu on Forefront Evacuating Indians from Maldives. https://t.co/voPQh6JXvn #IndiaFightsCorona https://t.co/MEQ70kow7b\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tC-fjPT_1lXI","colab_type":"code","colab":{}},"source":["df.to_csv('mygovfactcheck_data.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZEP8Z57V522p","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}